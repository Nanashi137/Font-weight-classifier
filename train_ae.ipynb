{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as L\n",
    "\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "from model.deepfont import DeepFont\n",
    "from model.lightning_generate_callback import GenerateCallback\n",
    "from model.lightning_wrappers import DeepFontAutoencoderWrapper, DeepFontWrapper\n",
    "\n",
    "from dataset.dataset import FontWeightDataset, FWDataset\n",
    "from dataset.transformations import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from model.configs import load_config\n",
    "import numpy as np\n",
    "import random \n",
    "import os \n",
    "import cv2 as cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"F:/FWC216/configs/adobe-vfr.yaml\")\n",
    "#config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "data_path = \"data/\"\n",
    "folders = os.listdir(data_path)\n",
    "\n",
    "img_paths = []\n",
    "\n",
    "for folder in folders: \n",
    "    cpath = data_path + folder \n",
    "\n",
    "    images = os.listdir(cpath)\n",
    "    for image in images: \n",
    "        a_path = \"F:/FWC216/\" + data_path + folder + \"/\" + image\n",
    "        img_paths.append(a_path)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = 0\n",
    "# for i in img_paths: \n",
    "#     print(i)\n",
    "#     img = cv.imread(i, cv.IMREAD_GRAYSCALE)\n",
    "#     np_img = np.array(img, dtype=np.uint8)\n",
    "#     z+=1\n",
    "#     print(z)\n",
    "#     print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split data\n",
    "\n",
    "random.shuffle(img_paths) \n",
    "\n",
    "total_size = len(img_paths)\n",
    "train_size = int(0.7*total_size)\n",
    "test_size  = int(0.1*total_size) \n",
    "valid_size =  total_size - train_size - test_size\n",
    "\n",
    "train_data = img_paths[:train_size]\n",
    "test_data  = img_paths[train_size:train_size + test_size]\n",
    "valid_data = img_paths[train_size + test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = T1()\n",
    "# for path in train_data: \n",
    "#     img = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "#     img1 = Ptrans(img)\n",
    "#     img2 = t(image=img)['image']\n",
    "#     print(img1.shape, img2.shape)\n",
    "#     break\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_img.shape\n",
    "# cv.imshow(\"n\", t_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch dataset\n",
    "\n",
    "\n",
    "train_dataset =  FWDataset(img_folder = train_data)\n",
    "test_dataset  =  FWDataset(img_folder = test_data )\n",
    "valid_dataset =  FWDataset(img_folder = valid_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader \n",
    "batch_size = 64\n",
    "train_loader =  DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers= 5, persistent_workers= True)\n",
    "\n",
    "valid_loader =  DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers= 5, persistent_workers= True)\n",
    "\n",
    "test_loader  =  DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers= 5, persistent_workers= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepFontAutoencoderWrapper(\n",
       "  (autoencoder): DeepFontAutoencoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(12, 12), stride=(2, 2), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (1): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): ReLU()\n",
       "      (3): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "      (4): ConvTranspose2d(64, 1, kernel_size=(12, 12), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (5): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model\n",
    "model = DeepFontAutoencoderWrapper()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: f:\\FWC216\\lightning_logs\n",
      "f:\\FWC\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory F:\\FWC216\\output_ae exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                  | Type                | Params | Mode  | In sizes         | Out sizes       \n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "0  | autoencoder           | DeepFontAutoencoder | 166 K  | train | [2, 1, 105, 105] | [2, 1, 105, 105]\n",
      "1  | autoencoder.encoder   | Sequential          | 83.5 K | train | [2, 1, 105, 105] | [2, 128, 12, 12]\n",
      "2  | autoencoder.encoder.0 | Conv2d              | 9.3 K  | train | [2, 1, 105, 105] | [2, 64, 48, 48] \n",
      "3  | autoencoder.encoder.1 | ReLU                | 0      | train | [2, 64, 48, 48]  | [2, 64, 48, 48] \n",
      "4  | autoencoder.encoder.2 | BatchNorm2d         | 128    | train | [2, 64, 48, 48]  | [2, 64, 48, 48] \n",
      "5  | autoencoder.encoder.3 | MaxPool2d           | 0      | train | [2, 64, 48, 48]  | [2, 64, 24, 24] \n",
      "6  | autoencoder.encoder.4 | Conv2d              | 73.9 K | train | [2, 64, 24, 24]  | [2, 128, 24, 24]\n",
      "7  | autoencoder.encoder.5 | ReLU                | 0      | train | [2, 128, 24, 24] | [2, 128, 24, 24]\n",
      "8  | autoencoder.encoder.6 | BatchNorm2d         | 256    | train | [2, 128, 24, 24] | [2, 128, 24, 24]\n",
      "9  | autoencoder.encoder.7 | MaxPool2d           | 0      | train | [2, 128, 24, 24] | [2, 128, 12, 12]\n",
      "10 | autoencoder.decoder   | Sequential          | 83.0 K | train | [2, 128, 12, 12] | [2, 1, 105, 105]\n",
      "11 | autoencoder.decoder.0 | Upsample            | 0      | train | [2, 128, 12, 12] | [2, 128, 24, 24]\n",
      "12 | autoencoder.decoder.1 | ConvTranspose2d     | 73.8 K | train | [2, 128, 24, 24] | [2, 64, 24, 24] \n",
      "13 | autoencoder.decoder.2 | ReLU                | 0      | train | [2, 64, 24, 24]  | [2, 64, 24, 24] \n",
      "14 | autoencoder.decoder.3 | Upsample            | 0      | train | [2, 64, 24, 24]  | [2, 64, 48, 48] \n",
      "15 | autoencoder.decoder.4 | ConvTranspose2d     | 9.2 K  | train | [2, 64, 48, 48]  | [2, 1, 105, 105]\n",
      "16 | autoencoder.decoder.5 | Sigmoid             | 0      | train | [2, 1, 105, 105] | [2, 1, 105, 105]\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "166 K     Trainable params\n",
      "0         Non-trainable params\n",
      "166 K     Total params\n",
      "0.666     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 438/438 [00:32<00:00, 13.49it/s, v_num=0, train_loss=0.000797, val_loss=0.000868]\n"
     ]
    }
   ],
   "source": [
    "# Define trainer \n",
    "\n",
    "training_callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", mode=\"min\"),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "        ModelCheckpoint(\n",
    "            dirpath=\"./output_ae\",\n",
    "            save_top_k=2,\n",
    "            monitor=\"val_loss\",\n",
    "            filename=\"deepfont-{epoch:02d}-{val_loss:.4f}-{val_accuracy:.4f}\",\n",
    "            save_last=True,\n",
    "        ),\n",
    "        ModelSummary(-1),\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "sample_index = 10 % len(train_dataset)\n",
    "training_callbacks.append(\n",
    "        GenerateCallback(\n",
    "            train_dataset[sample_index][0].unsqueeze(0), every_n_epochs=5\n",
    "        ),\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "        # If ever doing gradient clipping here, remember that this\n",
    "        # has an effect on training: it will take likely twice as\n",
    "        # long to get to the same accuracy!\n",
    "        # gradient_clip_algorithm=\"norm\",\n",
    "        # gradient_clip_val=1.0,\n",
    "    max_epochs=40,\n",
    "    callbacks=training_callbacks,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=valid_loader,\n",
    "    ckpt_path= None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 63/63 [00:07<00:00,  7.89it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.0008794337045401335\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0008794337045401335}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
